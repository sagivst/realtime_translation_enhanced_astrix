# Media Gateway Integration Plan for Extensions 7777 & 8888
**Working ONLY on VM: http://20.170.155.53/**
**NEVER touching production VM: http://4.185.84.26/**

## ðŸ“‹ CURRENT STATE ANALYSIS

### Existing AudioSocket System (Extensions 7000 & 7001) - **DO NOT TOUCH**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AUDIOSOCKET TRANSLATION FLOW (7000/7001)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT PATH (Microphone â†’ Translation):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SIP Phone (7000/7001)
   â”‚ Microphone Audio
   â†“
Asterisk (ExternalMedia dialplan)
   â”‚ AudioSocket Protocol (TCP)
   â”‚ 8kHz PCM, 3-byte header per frame
   â†“
AudioSocketOrchestrator (Ports 5050/5052)
   â”‚ UUID: "7000-xxxxx" or "7001-xxxxx"
   â”‚ Strips 3-byte header
   â†“
audiosocket-integration.js
   â”‚ Session Management: activeSessions.get(uuid)
   â”‚ Extension routing: getExtensionFromUUID(uuid)
   â†“
Translation Pipeline:
   â”œâ”€ ASRStreamingWorker (Deepgram STT) [8kHz input]
   â”‚    â””â”€ Event: 'transcript' â†’ translatedText
   â”œâ”€ DeepLIncrementalMT (DeepL Translation)
   â”‚    â””â”€ translator7000 for 7000, translator7001 for 7001
   â”œâ”€ ElevenLabsTTSService (Text-to-Speech)
   â”‚    â””â”€ Returns PCM 16kHz audio buffer
   â””â”€ AudioStreamBuffer (Latency Sync + Timing)
        â””â”€ Event: 'audioReady' â†’ pcmBuffer (16kHz)

OUTPUT PATH (Translated Audio â†’ Speaker):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AudioStreamBuffer
   â”‚ Event: 'audioReady'
   â†“
sendAudioToMicEndpoint(session.micWebSocket, pcmBuffer)
   â”‚ Amplify 500x
   â”‚ Frame size: 640 bytes (16kHz Ã— 20ms Ã— 2 bytes)
   â†“
WebSocket Connection
   â”‚ URL: ws://127.0.0.1:{targetPort}/mic/{uuid}
   â”‚ Port 5053 for Ext 7000 â†’ Audio goes to 7001's ear
   â”‚ Port 5051 for Ext 7001 â†’ Audio goes to 7000's ear
   â”‚ (CROSS-EXTENSION ROUTING)
   â†“
AudioSocketOrchestrator (Output ports 5051/5053)
   â”‚ Adds 3-byte AudioSocket header
   â”‚ Downsamples 16kHz â†’ 8kHz
   â†“
Asterisk (AudioSocket TCP connection)
   â”‚ Injects into bridge
   â†“
SIP Phone Speaker (Other extension hears translation)
```

**Key AudioSocket Components:**
- File: `audiosocket-integration.js` (MISSING in current branch!)
- UUID Format: `"7000-xxxxx"` or `"7001-xxxxx"`
- Input Protocol: TCP AudioSocket, 8kHz, 3-byte header
- Output Protocol: WebSocket â†’ AudioSocket, 16kHz downsampled to 8kHz
- Cross-routing: 7000 hears 7001's translation, 7001 hears 7000's translation
- Amplification: 500x on output

---

## ðŸŽ¯ NEW MEDIA GATEWAY SYSTEM (Extensions 7777 & 8888)

### Reference: Asterisk External Media Example
Based on `/Users/sagivstavinsky/realtime-translation-enhanced_astrix/asterisk-external-media/`:

**RTP UDP Server Pattern:**
```javascript
// From rtp-udp-server.js
this.server.on('message', (msg, rinfo) => {
    // Strip the 12 byte RTP header
    let buf = msg.slice(12);

    // Swap byte order if SLIN16 (big-endian â†’ little-endian)
    if (this.swap16) {
        buf.swap16();
    }

    // Emit 'data' event with raw PCM
    this.server.emit('data', buf);
});
```

**ARI Controller Pattern:**
```javascript
// From ari-controller.js
// 1. Create mixing bridge
await this.bridge.create({type: "mixing"});

// 2. Create local channel (dials extension)
await this.localChannel.originate({
    endpoint: dialstring,
    formats: 'slin16',
    app: "externalMedia"
});

// 3. Create ExternalMedia channel
await this.externalChannel.externalMedia({
    app: "externalMedia",
    external_host: '127.0.0.1:6000',  // Where to send RTP
    format: 'slin16'                   // 16kHz PCM
});

// 4. Add both channels to bridge
await this.bridge.addChannel({channel: localChannel.id});
await this.bridge.addChannel({channel: externalChannel.id});
```

### Proposed Media Gateway Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MEDIA GATEWAY TRANSLATION FLOW (7777/8888)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

INPUT PATH (Microphone â†’ Translation):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SIP Phone (7777/7888)
   â”‚ Microphone Audio
   â†“
Asterisk (ExternalMedia ARI)
   â”‚ RTP Protocol (UDP)
   â”‚ 16kHz PCM (slin16), 12-byte RTP header
   â”‚ Format: Big-endian
   â†“
Media Gateway RTP Listener (Port 17000 for 7777, 18000 for 8888)
   â”‚ Receives RTP packets via UDP
   â”‚ Strips 12-byte RTP header
   â”‚ UUID: "7777-{ssrc}" or "8888-{ssrc}"
   â”‚ Keep BIG-ENDIAN (NO byte swap for optimal quality)
   â†“
externalmedia-integration.js (NEW FILE - mirror of audiosocket-integration.js)
   â”‚ Session Management: activeSessions.get(uuid)
   â”‚ Extension routing: getExtensionFromUUID(uuid)
   â†“
Translation Pipeline: (SAME AS AUDIOSOCKET)
   â”œâ”€ ASRStreamingWorker (Deepgram STT) [16kHz input - BETTER QUALITY!]
   â”‚    â””â”€ Event: 'transcript' â†’ translatedText
   â”œâ”€ DeepLIncrementalMT (DeepL Translation)
   â”‚    â””â”€ translator7777 for 7777, translator7888 for 7888
   â”œâ”€ ElevenLabsTTSService (Text-to-Speech)
   â”‚    â””â”€ Returns PCM 16kHz audio buffer
   â””â”€ AudioStreamBuffer (Latency Sync + Timing)
        â””â”€ Event: 'audioReady' â†’ pcmBuffer (16kHz)

OUTPUT PATH (Translated Audio â†’ Speaker):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AudioStreamBuffer
   â”‚ Event: 'audioReady'
   â†“
sendAudioToMediaGateway(uuid, pcmBuffer)
   â”‚ NO amplification needed (RTP levels correct)
   â”‚ Keep 16kHz (no resampling!)
   â”‚ Add 12-byte RTP header
   â”‚ Keep BIG-ENDIAN format
   â†“
Media Gateway RTP Sender
   â”‚ Port 18000 for Ext 7777 â†’ Audio goes to 8888's ear
   â”‚ Port 17000 for Ext 8888 â†’ Audio goes to 7777's ear
   â”‚ (CROSS-EXTENSION ROUTING)
   â†“
Asterisk (ExternalMedia RTP bidirectional)
   â”‚ Injects into bridge via RTP
   â†“
SIP Phone Speaker (Other extension hears translation)
```

---

## ðŸ“ STEP-BY-STEP IMPLEMENTATION PLAN

### PHASE 1: Media Gateway RTP Handler (externalmedia-rtp-handler.js)

**Purpose:** UDP RTP receiver/sender for extensions 7777 and 8888

**File:** `/home/azureuser/translation-app/externalmedia-rtp-handler.js`

**Implementation:**
```javascript
const dgram = require('dgram');
const EventEmitter = require('events');

class MediaGatewayRTPHandler extends EventEmitter {
    constructor(extension, listenPort, sendPort) {
        super();
        this.extension = extension;
        this.listenPort = listenPort;
        this.sendPort = sendPort;
        this.sessions = new Map();  // SSRC â†’ session data

        // Create UDP socket for receiving RTP
        this.receiveSocket = dgram.createSocket('udp4');

        // Create UDP socket for sending RTP
        this.sendSocket = dgram.createSocket('udp4');
    }

    start() {
        // Listen for incoming RTP packets
        this.receiveSocket.on('message', (msg, rinfo) => {
            // Extract SSRC from RTP header (bytes 8-11)
            const ssrc = msg.readUInt32BE(8);
            const uuid = `${this.extension}-${ssrc}`;

            // Store remote address for sending back
            if (!this.sessions.has(uuid)) {
                this.sessions.set(uuid, {
                    remoteAddress: rinfo.address,
                    remotePort: rinfo.port,
                    sequenceNumber: 0,
                    timestamp: 0
                });
                console.log(`[MediaGateway] New session: ${uuid} from ${rinfo.address}:${rinfo.port}`);
            }

            // Strip 12-byte RTP header
            const pcmAudio = msg.slice(12);

            // NO byte swap - keep big-endian for optimal quality
            // NO amplification - RTP levels are correct

            // Emit audio event
            this.emit('audio', {
                uuid: uuid,
                extension: this.extension,
                audio: pcmAudio,
                sampleRate: 16000,
                channels: 1,
                bitDepth: 16
            });
        });

        this.receiveSocket.bind(this.listenPort, '127.0.0.1');
        console.log(`[MediaGateway] Ext ${this.extension} listening on UDP port ${this.listenPort}`);
    }

    sendAudio(uuid, pcmBuffer) {
        const session = this.sessions.get(uuid);
        if (!session) {
            console.warn(`[MediaGateway] No session found for ${uuid}`);
            return;
        }

        // Create RTP header (12 bytes)
        const rtpHeader = Buffer.alloc(12);
        rtpHeader[0] = 0x80;  // Version 2, no padding, no extension
        rtpHeader[1] = 0x0B;  // Payload type 11 (L16 stereo) - use 0x0A for mono

        // Increment sequence number
        session.sequenceNumber = (session.sequenceNumber + 1) & 0xFFFF;
        rtpHeader.writeUInt16BE(session.sequenceNumber, 2);

        // Increment timestamp (160 samples per 20ms frame at 16kHz)
        session.timestamp += 160;
        rtpHeader.writeUInt32BE(session.timestamp, 4);

        // SSRC (extract from UUID)
        const ssrc = parseInt(uuid.split('-')[1]);
        rtpHeader.writeUInt32BE(ssrc, 8);

        // Combine header + audio
        const rtpPacket = Buffer.concat([rtpHeader, pcmBuffer]);

        // Send to remote address
        this.sendSocket.send(
            rtpPacket,
            this.sendPort,
            session.remoteAddress,
            (err) => {
                if (err) {
                    console.error(`[MediaGateway] Send error for ${uuid}:`, err);
                }
            }
        );
    }

    close() {
        this.receiveSocket.close();
        this.sendSocket.close();
    }
}

module.exports = MediaGatewayRTPHandler;
```

**Key Differences from AudioSocket:**
| Aspect | AudioSocket (7000/7001) | MediaGateway (7777/8888) |
|--------|------------------------|--------------------------|
| Protocol | TCP | UDP (RTP) |
| Sample Rate | 8kHz | 16kHz (BETTER QUALITY) |
| Header | 3 bytes (custom) | 12 bytes (RTP standard) |
| Byte Order | Little-endian (swap needed) | Big-endian (NO swap) |
| Amplification | 500x on output | NONE (RTP levels correct) |
| Frame Size | Variable | 320 bytes (20ms @ 16kHz) |
| Ports | 5050-5057 | 17000, 18000 |

---

### PHASE 2: Media Gateway Integration Layer (externalmedia-integration.js)

**Purpose:** Mirror of audiosocket-integration.js for Media Gateway

**File:** `/home/azureuser/translation-app/externalmedia-integration.js`

**Structure (based on audiosocket-integration.js):**
```javascript
// ============================================================================
// Complete MediaGateway Pipeline: STT â†’ Translation â†’ TTS
// Asterisk (RTP) â†’ Deepgram â†’ DeepL â†’ ElevenLabs (PCM) â†’ Asterisk (RTP)
// Uses 16kHz throughout - NO resampling needed!
// Extensions 7777 and 8888 bidirectional translation
// ============================================================================

require('dotenv').config();

const MediaGatewayRTPHandler = require('./externalmedia-rtp-handler');
const { ASRStreamingWorker } = require('./asr-streaming-worker');
const { DeepLIncrementalMT } = require('./deepl-incremental-mt');
const ElevenLabsTTSService = require('./elevenlabs-tts-service');
const AudioStreamBuffer = require('./audio-stream-buffer');

// Get API keys
const deepgramApiKey = process.env.DEEPGRAM_API_KEY;
const deeplApiKey = process.env.DEEPL_API_KEY;
const deeplApiKey7888 = process.env.DEEPL_API_KEY_7888 || deeplApiKey;
const elevenlabsApiKey = process.env.ELEVENLABS_API_KEY;

console.log('[MediaGateway] Initializing translation pipeline...');
console.log('[MediaGateway] Deepgram:', deepgramApiKey ? 'âœ“' : 'âœ—');
console.log('[MediaGateway] DeepL:', deeplApiKey ? 'âœ“' : 'âœ—');
console.log('[MediaGateway] ElevenLabs:', elevenlabsApiKey ? 'âœ“' : 'âœ—');

// Initialize RTP handlers
const mediaGateway7777 = new MediaGatewayRTPHandler('7777', 17000, 18000);
const mediaGateway8888 = new MediaGatewayRTPHandler('8888', 18000, 17000);

// Start listening
mediaGateway7777.start();
mediaGateway8888.start();

// Initialize translation services
const translator7777 = deeplApiKey ? new DeepLIncrementalMT(deeplApiKey) : null;
const translator8888 = deeplApiKey7888 ? new DeepLIncrementalMT(deeplApiKey7888) : null;
const ttsService = elevenlabsApiKey ? new ElevenLabsTTSService(elevenlabsApiKey) : null;

// Session management
const activeSessions = new Map();

function getExtensionFromUUID(uuid) {
    if (!uuid) return null;
    if (uuid === "7777" || uuid === "7888") return uuid;
    if (uuid.startsWith("7777")) return "7777";
    if (uuid.startsWith("8888")) return "8888";
    return null;
}

function getTranslator(extension) {
    console.log("[DeepL Router] Extension:", extension,
                "-> Using translator7777:", (extension !== "8888"),
                "translator8888:", (extension === "8888"));
    if (extension === "8888") return translator8888;
    return translator7777;
}

function getSession(uuid, extensionId) {
    if (!activeSessions.has(uuid)) {
        console.log('[MediaGateway] Creating new session for:', uuid);
        const extension = extensionId || getExtensionFromUUID(uuid);
        activeSessions.set(uuid, {
            uuid: uuid,
            extension: extension,
            asrWorker: null,
            audioStreamBuffer: null,
            created: Date.now()
        });
    }
    return activeSessions.get(uuid);
}

// Handle incoming audio from RTP
mediaGateway7777.on('audio', (data) => {
    handleIncomingAudio(data);
});

mediaGateway8888.on('audio', (data) => {
    handleIncomingAudio(data);
});

function handleIncomingAudio(data) {
    const { uuid, extension, audio } = data;

    // Get or create session
    let session = getSession(uuid, extension);

    // Initialize ASR worker if needed
    if (!session.asrWorker) {
        initializeASRWorker(uuid);
    }

    // Initialize Audio Stream Buffer if needed
    if (!session.audioStreamBuffer) {
        initializeAudioStreamBuffer(uuid);
    }

    // Send audio to ASR (16kHz - better quality than 8kHz!)
    session.asrWorker.sendAudio(audio, {
        segmentId: Date.now(),
        duration: 20  // 20ms frames
    });
}

function initializeASRWorker(uuid) {
    const session = getSession(uuid);
    const qaConfig = global.qaConfigs?.get(session.extension) || {};

    console.log('[MediaGateway] Initializing ASR for:', uuid);

    session.asrWorker = new ASRStreamingWorker(deepgramApiKey, {
        language: qaConfig.sourceLang || 'en',
        model: 'nova-2',
        sampleRate: 16000,  // 16kHz for better quality!
        encoding: 'linear16',
        channels: 1
    });

    session.asrWorker.on('transcript', async (transcript) => {
        await handleTranscript(uuid, transcript);
    });

    session.asrWorker.start();
}

function initializeAudioStreamBuffer(uuid) {
    const session = getSession(uuid);

    console.log('[MediaGateway] Initializing AudioStreamBuffer for:', uuid);

    session.audioStreamBuffer = new AudioStreamBuffer({
        sampleRate: 16000,  // 16kHz - NO resampling needed!
        channels: 1,
        bitDepth: 16,
        maxBufferSize: 2000
    });

    // Listen for processed audio
    session.audioStreamBuffer.on('audioReady', (audioData) => {
        const pcmBuffer = audioData.buffer;
        sendAudioToMediaGateway(uuid, pcmBuffer);
    });
}

async function handleTranscript(uuid, transcript) {
    const session = getSession(uuid);
    const qaConfig = global.qaConfigs?.get(session.extension) || {};

    console.log(`[MediaGateway] ${uuid} Transcript:`, transcript.text);

    // Translate
    const translator = getTranslator(session.extension);
    const translatedText = await translator.translate(
        transcript.text,
        qaConfig.sourceLang || 'en',
        qaConfig.targetLang || 'es'
    );

    console.log(`[MediaGateway] ${uuid} Translation:`, translatedText);

    // TTS
    const audioBuffer = await ttsService.synthesize(translatedText, {
        voiceId: getVoiceForExtension(session.extension),
        outputFormat: 'pcm_16000'  // 16kHz PCM
    });

    // Add to buffer for latency sync
    session.audioStreamBuffer.addAudio(audioBuffer);
}

function sendAudioToMediaGateway(uuid, pcmBuffer) {
    const session = getSession(uuid);

    // Get target extension (cross-routing)
    const targetExtension = (session.extension === '7777') ? '8888' : '7777';

    // Get target MediaGateway handler
    const targetGateway = (targetExtension === '7777') ? mediaGateway7777 : mediaGateway8888;

    // Create target UUID (use same SSRC for routing)
    const ssrc = uuid.split('-')[1];
    const targetUUID = `${targetExtension}-${ssrc}`;

    console.log(`[MediaGateway] Sending audio from ${uuid} to ${targetUUID}`);

    // Send via RTP (NO amplification, NO resampling)
    targetGateway.sendAudio(targetUUID, pcmBuffer);
}

function getVoiceForExtension(extension) {
    const qaConfig = global.qaConfigs?.get(extension) || {};
    // Return appropriate voice based on target language
    return qaConfig.targetLang === 'es' ? 'spanish_voice_id' : 'english_voice_id';
}

// Export for cleanup
module.exports = {
    mediaGateway7777,
    mediaGateway8888,
    activeSessions
};
```

---

### PHASE 3: Modify conference-server.js

**Changes Required:**

#### 3a. Add QA Configs for 7777/8888
```javascript
// After existing QA configs for 7000/7001
global.qaConfigs.set('7777', {
    sourceLang: 'en',
    targetLang: 'es',
    qaMode: false
});

global.qaConfigs.set('8888', {
    sourceLang: 'es',
    targetLang: 'en',
    qaMode: false
});

console.log('[QA Config] Extensions 7777/8888 configured');
```

#### 3b. Load MediaGateway Integration
```javascript
// After audiosocket-integration (if present)
try {
    require('./externalmedia-integration');
    console.log('[MediaGateway] Integration loaded for extensions 7777, 8888');
} catch (error) {
    console.error('[MediaGateway] Failed to load integration:', error.message);
}
```

---

### PHASE 4: Update Asterisk Configuration

**File:** `/etc/asterisk/extensions.conf`

```ini
[from-internal]
; Existing AudioSocket extensions - DO NOT MODIFY
exten => 7000,1,NoOp(Call to translation extension 7000)
exten => 7000,n,AudioSocket(...)
exten => 7001,1,NoOp(Call to translation extension 7001)
exten => 7001,n,AudioSocket(...)

; NEW: Media Gateway extensions using ExternalMedia + ARI
exten => 7777,1,NoOp(Call to MediaGateway extension 7777)
exten => 7777,n,Answer()
exten => 7777,n,Stasis(media-gateway-translation,7777)
exten => 7777,n,Hangup()

exten => 8888,1,NoOp(Call to MediaGateway extension 8888)
exten => 8888,n,Answer()
exten => 8888,n,Stasis(media-gateway-translation,8888)
exten => 8888,n,Hangup()
```

---

### PHASE 5: Create ARI Handler for Media Gateway

**File:** `/home/azureuser/translation-app/media-gateway-ari-handler.js`

**Purpose:** Handle ARI Stasis events and create ExternalMedia channels

```javascript
const ari = require('ari-client');

const ARI_URL = 'http://localhost:8088';
const ARI_USER = process.env.ASTERISK_ARI_USERNAME || 'dev';
const ARI_PASS = process.env.ASTERISK_ARI_PASSWORD || 'asterisk';
const APP_NAME = 'media-gateway-translation';

// RTP configuration
const CONFIG = {
    '7777': {
        bridgeId: 'bridge-7777',
        rtpHost: '127.0.0.1:17000'  // Where Asterisk sends/receives RTP
    },
    '8888': {
        bridgeId: 'bridge-8888',
        rtpHost: '127.0.0.1:18000'
    }
};

console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
console.log('â•‘  Media Gateway ARI Handler                                 â•‘');
console.log('â•‘  Extensions 7777 and 8888 bidirectional translation        â•‘');
console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

ari.connect(ARI_URL, ARI_USER, ARI_PASS)
    .then(client => {
        console.log('âœ“ ARI Connected to Asterisk');

        client.on('StasisStart', async (event, channel) => {
            const extension = event.args[0];  // '7777' or '8888'

            console.log(`[${extension}] User channel entered Stasis: ${channel.id}`);

            if (!CONFIG[extension]) {
                console.error(`[${extension}] âœ— Invalid extension`);
                return channel.hangup().catch(() => {});
            }

            const config = CONFIG[extension];

            try {
                // 1. Create or get mixing bridge
                let bridge;
                try {
                    bridge = await client.bridges.get({ bridgeId: config.bridgeId });
                    console.log(`[${extension}] âœ“ Bridge exists: ${config.bridgeId}`);
                } catch (e) {
                    bridge = await client.bridges.create({
                        type: 'mixing',
                        name: config.bridgeId,
                        bridgeId: config.bridgeId
                    });
                    console.log(`[${extension}] âœ“ Created bridge: ${config.bridgeId}`);
                }

                // 2. Add user channel to bridge
                await bridge.addChannel({ channel: channel.id });
                console.log(`[${extension}] âœ“ User channel added to bridge`);

                // 3. Create ExternalMedia channel for bidirectional RTP
                const externalChannelId = `external-${extension}-${Date.now()}`;
                const externalChannel = await client.channels.externalMedia({
                    app: APP_NAME,
                    external_host: config.rtpHost,
                    format: 'slin16',  // 16kHz PCM
                    channelId: externalChannelId
                });
                console.log(`[${extension}] âœ“ ExternalMedia channel created: ${externalChannel.id}`);

                // 4. Add ExternalMedia channel to bridge
                await bridge.addChannel({ channel: externalChannel.id });
                console.log(`[${extension}] âœ“ ExternalMedia channel added to bridge`);

                console.log(`[${extension}] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
                console.log(`[${extension}] âœ“ Translation channel READY`);
                console.log(`[${extension}] Bridge: ${config.bridgeId}`);
                console.log(`[${extension}] RTP: ${config.rtpHost}`);

            } catch (error) {
                console.error(`[${extension}] âœ— Setup failed:`, error.message);
                channel.hangup().catch(() => {});
            }
        });

        client.on('StasisEnd', (event, channel) => {
            console.log(`[ARI] Channel left Stasis: ${channel.id}`);
        });

        client.start(APP_NAME);
        console.log(`âœ“ ARI application started: ${APP_NAME}`);

    })
    .catch(error => {
        console.error('âœ— ARI Connection failed:', error.message);
        process.exit(1);
    });

module.exports = {};
```

---

### PHASE 6: Load ARI Handler in conference-server.js

```javascript
// After loading externalmedia-integration
try {
    require('./media-gateway-ari-handler');
    console.log('[ARI] Media Gateway ARI handler loaded');
} catch (error) {
    console.error('[ARI] Failed to load handler:', error.message);
}
```

---

## ðŸ”„ COMPLETE DATA FLOW DIAGRAM

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PARALLEL TRANSLATION SYSTEMS                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

SYSTEM 1: AudioSocket (7000 â†” 7001) - UNTOUCHED
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SIP 7000 â†’ Asterisk â†’ AudioSocket (TCP 5050, 8kHz)
         â†’ audiosocket-integration.js
         â†’ [STT â†’ MT â†’ TTS â†’ LS Buffer]
         â†’ WebSocket (16kHz) â†’ AudioSocket (5053, 8kHz)
         â†’ Asterisk â†’ SIP 7001 (hears 7000's translation)

SIP 7001 â†’ Asterisk â†’ AudioSocket (TCP 5052, 8kHz)
         â†’ audiosocket-integration.js
         â†’ [STT â†’ MT â†’ TTS â†’ LS Buffer]
         â†’ WebSocket (16kHz) â†’ AudioSocket (5051, 8kHz)
         â†’ Asterisk â†’ SIP 7000 (hears 7001's translation)

SYSTEM 2: Media Gateway (7777 â†” 8888) - NEW
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SIP 7777 â†’ Asterisk â†’ ARI Stasis â†’ ExternalMedia (RTP UDP 17000, 16kHz)
         â†’ MediaGatewayRTPHandler
         â†’ externalmedia-integration.js
         â†’ [STT â†’ MT â†’ TTS â†’ LS Buffer]
         â†’ MediaGatewayRTPHandler (18000, 16kHz)
         â†’ ExternalMedia â†’ Asterisk â†’ SIP 8888 (hears 7777's translation)

SIP 8888 â†’ Asterisk â†’ ARI Stasis â†’ ExternalMedia (RTP UDP 18000, 16kHz)
         â†’ MediaGatewayRTPHandler
         â†’ externalmedia-integration.js
         â†’ [STT â†’ MT â†’ TTS â†’ LS Buffer]
         â†’ MediaGatewayRTPHandler (17000, 16kHz)
         â†’ ExternalMedia â†’ Asterisk â†’ SIP 7777 (hears 8888's translation)

SHARED COMPONENTS:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- ASRStreamingWorker (Deepgram STT)
- DeepLIncrementalMT (DeepL Translation)
- ElevenLabsTTSService (Text-to-Speech)
- AudioStreamBuffer (Latency Sync + Timing)
- global.qaConfigs (Language configuration)
```

---

## ðŸ“Š COMPARISON TABLE

| Feature | AudioSocket (7000/7001) | Media Gateway (7777/8888) |
|---------|------------------------|---------------------------|
| **Protocol** | TCP AudioSocket | UDP RTP |
| **Sample Rate** | 8kHz | **16kHz** (better quality!) |
| **Audio Format** | PCM with 3-byte header | PCM with 12-byte RTP header |
| **Byte Order** | Little-endian (needs swap) | Big-endian (no swap) |
| **Input Ports** | 5050, 5052 (TCP) | 17000, 18000 (UDP) |
| **Output Ports** | 5051, 5053 (TCP) | 18000, 17000 (UDP) |
| **Amplification** | 500x on output | **NONE** (RTP levels correct) |
| **Resampling** | 16kHz â†’ 8kHz on output | **NONE** (16kHz throughout) |
| **Integration File** | audiosocket-integration.js | externalmedia-integration.js |
| **ARI Required** | No | **Yes** |
| **File Status** | MISSING in current branch | **NEW - to be created** |
| **Extensions** | 7000 â†” 7001 | 7777 â†” 8888 |
| **Cross-routing** | Via WebSocket ports | Via RTP handlers |

---

## âœ… IMPLEMENTATION CHECKLIST

### Pre-Implementation
- [ ] Backup current working state: `git branch backup-$(date +%Y%m%d-%H%M%S)`
- [ ] Verify VM: **Working ONLY on http://20.170.155.53/**
- [ ] Confirm AudioSocket system (7000/7001) still working
- [ ] Review all files marked for creation

### Phase 1: RTP Handler
- [ ] Create `/home/azureuser/translation-app/externalmedia-rtp-handler.js`
- [ ] Test UDP listening on ports 17000 and 18000
- [ ] Verify RTP header stripping (12 bytes)
- [ ] Test audio emission events

### Phase 2: Integration Layer
- [ ] Create `/home/azureuser/translation-app/externalmedia-integration.js`
- [ ] Mirror structure from audiosocket-integration.js
- [ ] Initialize MediaGatewayRTPHandler instances
- [ ] Set up session management with UUID format "7777-{ssrc}", "8888-{ssrc}"
- [ ] Connect to translation pipeline (STT â†’ MT â†’ TTS â†’ LS Buffer)
- [ ] Implement cross-extension routing (7777 â†’ 8888, 8888 â†’ 7777)

### Phase 3: ARI Handler
- [ ] Create `/home/azureuser/translation-app/media-gateway-ari-handler.js`
- [ ] Connect to Asterisk ARI
- [ ] Handle StasisStart events
- [ ] Create mixing bridges for 7777 and 8888
- [ ] Create ExternalMedia channels with correct RTP endpoints

### Phase 4: Server Configuration
- [ ] Add QA configs for 7777/8888 in conference-server.js
- [ ] Load externalmedia-integration.js
- [ ] Load media-gateway-ari-handler.js
- [ ] Verify no conflicts with AudioSocket system

### Phase 5: Asterisk Configuration
- [ ] Update `/etc/asterisk/extensions.conf` with 7777/8888 dialplan
- [ ] Reload Asterisk dialplan: `asterisk -rx "dialplan reload"`
- [ ] Verify ARI user credentials in `/etc/asterisk/ari.conf`

### Phase 6: Testing
- [ ] Start conference-server.js
- [ ] Verify both systems load without errors
- [ ] Check UDP ports 17000, 18000 are listening
- [ ] Test SIP call to 7777
- [ ] Test SIP call to 8888
- [ ] Verify cross-extension translation (7777 hears 8888, 8888 hears 7777)
- [ ] Check audio quality (16kHz should be clearer than 8kHz)
- [ ] Verify AudioSocket system (7000/7001) still works
- [ ] Monitor latency and sync timing
- [ ] Check for echo or feedback issues

### Post-Implementation
- [ ] Document any issues encountered
- [ ] Create git checkpoint if successful
- [ ] Update monitoring dashboards if needed

---

## âš ï¸ CRITICAL CONSTRAINTS

1. **NEVER touch extensions 7000/7001** âœ“
2. **NEVER touch audiosocket-integration.js** (it's missing anyway) âœ“
3. **Keep AudioSocket system 100% operational** âœ“
4. **No byte swapping for RTP** (keep big-endian) âœ“
5. **No unnecessary amplification** (RTP levels correct) âœ“
6. **Maintain UUID format**: `{extension}-{identifier}` âœ“
7. **16kHz throughout** (no resampling) âœ“
8. **Work ONLY on VM http://20.170.155.53/** âœ“
9. **NEVER touch VM http://4.185.84.26/** âœ“

---

## ðŸŽ¯ SUCCESS CRITERIA

The integration is complete when:
1. âœ“ Two SIP phones can call 7777 and 8888
2. âœ“ They hear each other's translated speech in real-time
3. âœ“ Latency is similar to AudioSocket system (~1-2 seconds)
4. âœ“ No echo, feedback, or audio quality issues
5. âœ“ Audio quality is noticeably better (16kHz vs 8kHz)
6. âœ“ Extensions 7000/7001 remain completely functional
7. âœ“ System is stable for long calls (>5 minutes)
8. âœ“ Cross-extension routing works correctly (7777 â†” 8888)

---

## ðŸš€ ESTIMATED TIMELINE

- **Phase 1 (RTP Handler):** 1-2 hours
- **Phase 2 (Integration Layer):** 3-4 hours (largest file, ~1200 lines)
- **Phase 3 (ARI Handler):** 1 hour
- **Phase 4 (Server Config):** 30 minutes
- **Phase 5 (Asterisk Config):** 30 minutes
- **Phase 6 (Testing):** 2-3 hours

**Total Estimated:** 8-11 hours

---

*Plan created: 2025-11-05*
*Target VM: http://20.170.155.53/ ONLY*
*Status: Ready for implementation*
