<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HMLCP System Flow - Live Azure Demo</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            max-width: 1400px;
            width: 100%;
            margin: 0 auto;
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.8em;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.3em;
            opacity: 0.9;
        }

        .azure-badge {
            display: inline-block;
            background: rgba(255,255,255,0.2);
            padding: 10px 20px;
            border-radius: 25px;
            margin-top: 15px;
            font-size: 0.9em;
        }

        .azure-link {
            color: #ffd700;
            text-decoration: none;
            font-weight: bold;
        }

        .azure-link:hover {
            text-decoration: underline;
        }

        .legend {
            display: flex;
            justify-content: center;
            gap: 20px;
            padding: 20px;
            background: #f8f9fa;
            flex-wrap: wrap;
        }

        .legend-item {
            display: flex;
            align-items: center;
            gap: 10px;
            padding: 10px 20px;
            border-radius: 25px;
            font-weight: bold;
        }

        .legend-client {
            background: #fff3e0;
            color: #e65100;
            border: 2px solid #e65100;
        }

        .legend-external {
            background: #ffe5e5;
            color: #ff6b6b;
            border: 2px solid #ff6b6b;
        }

        .legend-hmlcp {
            background: #e5ffe5;
            color: #2f9e44;
            border: 2px solid #51cf66;
        }

        .legend-internal {
            background: #e5f3ff;
            color: #1971c2;
            border: 2px solid #4dabf7;
        }

        .legend-storage {
            background: #fff9db;
            color: #e67700;
            border: 2px solid #fcc419;
        }

        .progress-bar {
            height: 8px;
            background: #e9ecef;
            margin: 0 40px;
            border-radius: 5px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            width: 0;
            transition: width 0.5s ease;
        }

        .data-flow {
            text-align: center;
            margin: 20px 0;
            font-size: 1.3em;
            color: #667eea;
            font-weight: bold;
        }

        .flow-container {
            padding: 40px;
            max-height: 70vh;
            overflow-y: auto;
        }

        .step {
            margin-bottom: 30px;
            padding: 25px;
            border-radius: 15px;
            background: #f8f9fa;
            opacity: 0.3;
            transform: translateX(-20px);
            transition: all 0.5s ease;
            border-left: 5px solid #ddd;
        }

        .step.active {
            opacity: 1;
            transform: translateX(0);
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
        }

        .step.client {
            background: #fff3e0;
            border-left-color: #e65100;
        }

        .step.client.active {
            animation: pulse-orange 2s infinite;
        }

        .step.external {
            background: #ffe5e5;
            border-left-color: #ff6b6b;
        }

        .step.external.active {
            animation: pulse-red 2s infinite;
        }

        .step.hmlcp {
            background: #e5ffe5;
            border-left-color: #51cf66;
        }

        .step.hmlcp.active {
            animation: pulse-green 2s infinite;
        }

        .step.internal {
            background: #e5f3ff;
            border-left-color: #4dabf7;
        }

        .step.internal.active {
            animation: pulse-blue 2s infinite;
        }

        .step.storage {
            background: #fff9db;
            border-left-color: #fcc419;
        }

        .step.storage.active {
            animation: pulse-yellow 2s infinite;
        }

        @keyframes pulse-orange {
            0%, 100% { box-shadow: 0 5px 20px rgba(230,81,0,0.3); }
            50% { box-shadow: 0 5px 30px rgba(230,81,0,0.6); }
        }

        @keyframes pulse-red {
            0%, 100% { box-shadow: 0 5px 20px rgba(255,107,107,0.3); }
            50% { box-shadow: 0 5px 30px rgba(255,107,107,0.6); }
        }

        @keyframes pulse-green {
            0%, 100% { box-shadow: 0 5px 20px rgba(81,207,102,0.3); }
            50% { box-shadow: 0 5px 30px rgba(81,207,102,0.6); }
        }

        @keyframes pulse-blue {
            0%, 100% { box-shadow: 0 5px 20px rgba(77,171,247,0.3); }
            50% { box-shadow: 0 5px 30px rgba(77,171,247,0.6); }
        }

        @keyframes pulse-yellow {
            0%, 100% { box-shadow: 0 5px 20px rgba(252,196,25,0.3); }
            50% { box-shadow: 0 5px 30px rgba(252,196,25,0.6); }
        }

        .step-header {
            display: flex;
            align-items: center;
            cursor: pointer;
        }

        .step-number {
            font-size: 2em;
            font-weight: bold;
            min-width: 60px;
            height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
            background: white;
            border-radius: 50%;
            margin-right: 20px;
            box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        }

        .step-content {
            flex: 1;
        }

        .step-title {
            font-size: 1.6em;
            font-weight: bold;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
        }

        .step-description {
            color: #555;
            line-height: 1.8;
            margin-bottom: 15px;
            font-size: 1.05em;
        }

        .step-data {
            color: #667eea;
            font-weight: bold;
            margin: 15px 0;
            padding: 12px;
            background: rgba(102, 126, 234, 0.1);
            border-radius: 8px;
            font-size: 1.05em;
        }

        .step-code {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 15px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            margin-top: 15px;
            overflow-x: auto;
            line-height: 1.5;
        }

        .step-details {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease;
            margin-top: 15px;
        }

        .step-details.expanded {
            max-height: 2000px;
        }

        .details-section {
            background: rgba(0,0,0,0.03);
            padding: 20px;
            border-radius: 10px;
            margin-top: 15px;
        }

        .details-title {
            font-size: 1.2em;
            font-weight: bold;
            color: #333;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .details-content {
            color: #555;
            line-height: 1.8;
            margin-bottom: 10px;
        }

        .details-list {
            list-style: none;
            padding-left: 20px;
            margin: 10px 0;
        }

        .details-list li {
            padding: 5px 0;
            position: relative;
        }

        .details-list li:before {
            content: "▸";
            position: absolute;
            left: -15px;
            color: #667eea;
            font-weight: bold;
        }

        .file-ref {
            background: #2d2d2d;
            color: #4dabf7;
            padding: 3px 8px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }

        .metric {
            background: #e5ffe5;
            color: #2f9e44;
            padding: 8px 12px;
            border-radius: 6px;
            display: inline-block;
            margin: 5px 5px 5px 0;
            font-weight: bold;
        }

        .drill-btn {
            background: #667eea;
            color: white;
            border: none;
            padding: 8px 20px;
            border-radius: 20px;
            cursor: pointer;
            font-weight: bold;
            margin-top: 10px;
            transition: all 0.3s ease;
        }

        .drill-btn:hover {
            background: #764ba2;
            transform: translateY(-2px);
        }

        .drill-btn.expanded:after {
            content: " ▲";
        }

        .drill-btn:not(.expanded):after {
            content: " ▼";
        }

        .badge {
            display: inline-block;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 0.75em;
            font-weight: bold;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }

        .badge-client {
            background: #e65100;
            color: white;
        }

        .badge-external {
            background: #ff6b6b;
            color: white;
        }

        .badge-hmlcp {
            background: #51cf66;
            color: white;
        }

        .badge-internal {
            background: #4dabf7;
            color: white;
        }

        .badge-storage {
            background: #fcc419;
            color: #333;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            padding: 30px;
            background: #f8f9fa;
            flex-wrap: wrap;
        }

        .btn {
            padding: 15px 40px;
            font-size: 1.1em;
            border: none;
            border-radius: 10px;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: bold;
        }

        .btn-primary {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }

        .btn-primary:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 20px rgba(102,126,234,0.4);
        }

        .btn-secondary {
            background: white;
            color: #667eea;
            border: 2px solid #667eea;
        }

        .btn-secondary:hover {
            background: #667eea;
            color: white;
        }

        .btn-success {
            background: #51cf66;
            color: white;
        }

        .btn-success:hover {
            background: #2f9e44;
            transform: translateY(-2px);
        }

        .code-highlight {
            background: #4dabf7;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.95em;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>🎯 HMLCP System Flow</h1>
            <p>Human-Machine Language Calibration Protocol</p>
            <div class="azure-badge">
                🌐 Live on Azure:
                <a href="https://realtime-translation-1760218638.azurewebsites.net"
                   target="_blank"
                   class="azure-link">realtime-translation-1760218638.azurewebsites.net</a>
            </div>
        </div>

        <div class="legend">
            <div class="legend-item legend-client">🖥️ CLIENT LAYER</div>
            <div class="legend-item legend-external">🔴 EXTERNAL APIs</div>
            <div class="legend-item legend-hmlcp">🟢 HMLCP SYSTEM</div>
            <div class="legend-item legend-internal">🔵 SERVER INTERNAL</div>
            <div class="legend-item legend-storage">🟡 PERSISTENT STORAGE</div>
        </div>

        <div class="progress-bar">
            <div class="progress-fill" id="progress"></div>
        </div>

        <div class="data-flow" id="dataFlow"></div>

        <div class="flow-container" id="flowContainer">
            <!-- Steps will be inserted here by JavaScript -->
        </div>

        <div class="controls">
            <button class="btn btn-secondary" onclick="prevStep()">← Previous</button>
            <button class="btn btn-primary" onclick="nextStep()">Next →</button>
            <button class="btn btn-secondary" onclick="restart()">⟳ Restart</button>
            <button class="btn btn-success" onclick="window.open('/', '_blank')">🚀 Try Live Demo</button>
        </div>
    </div>

    <script>
        const steps = [
            {
                type: 'client',
                title: '👤 User Speaking',
                description: 'User speaks into the microphone in the browser. Audio is captured using WebRTC MediaRecorder API and sent to the Azure-hosted server via WebSocket.',
                data: '📊 Data Flow: Raw Audio Buffer (PCM format) → Azure Web App',
                code: `// CLIENT: index.html
socket.emit("audio-stream", {
  audioBuffer: audioData,
  roomId: currentRoom,
  userId: username
});

// WebSocket connection to Azure
const socket = io('https://realtime-translation-1760218638.azurewebsites.net');`,
                details: {
                    layer: 'Client Browser (JavaScript)',
                    technology: 'WebRTC MediaRecorder API + Socket.IO',
                    implementation: [
                        'Audio captured from microphone using getUserMedia()',
                        'MediaRecorder converts to PCM audio chunks',
                        'Chunks sent to Azure server in real-time via WebSocket',
                        'Bidirectional Socket.IO connection maintained',
                        'Azure WebSocket support enabled for persistent connections'
                    ],
                    files: [
                        'public/index.html - WebRTC audio capture',
                        'public/js/* - Socket.IO client logic'
                    ],
                    performance: '~50ms latency per audio chunk',
                    dataFormat: 'PCM 16-bit, 16kHz sample rate',
                    azure: 'WebSocket connections handled by Azure App Service with always-on enabled'
                }
            },
            {
                type: 'internal',
                title: '📋 Load User Profile (BEFORE STT)',
                description: 'Azure server receives audio and IMMEDIATELY loads the user\'s HMLCP profile from storage. This profile contains linguistic characteristics, phrase mappings, and custom vocabulary. The custom vocabulary is generated from bias terms to boost STT accuracy.',
                data: '📊 Data Flow: User Profile JSON + Generated Custom Vocabulary Array',
                code: `// SERVER: conference-server.js:318-323
// HMLCP: Get user profile BEFORE transcription
const { profile, uloLayer, patternExtractor } =
  await getUserProfile(participant.username, participant.language);

const customVocab = uloLayer.generateCustomVocabulary();
// Returns: [{ phrase: "Kubernetes", boost: 25 }, ...]`,
                details: {
                    layer: 'Conference Server (Internal) - Azure Node.js Runtime',
                    technology: 'Node.js + HMLCP User Profile Manager',
                    implementation: [
                        'getUserProfile() loads from hmlcp/profiles/<userId>_<language>.json',
                        'Profile cached in memory after first load (~10ms subsequent)',
                        'ULO Layer generates custom vocabulary from biasTerms array',
                        'Each term gets boost value (default: 25) for Deepgram',
                        'PatternExtractor ready for linguistic analysis',
                        'Azure file system stores persistent profiles'
                    ],
                    files: [
                        'conference-server.js:202-225 - getUserProfile helper',
                        'hmlcp/user-profile.js - UserProfile class',
                        'hmlcp/ulo-layer.js:generateCustomVocabulary()',
                        'hmlcp/profiles/*.json - Persistent storage on Azure'
                    ],
                    performance: 'First load: ~10ms | Cached: <1ms',
                    dataStructure: `{
  userId: "testuser",
  language: "en",
  biasTerms: ["Kubernetes", "PostgreSQL", "Azure"],
  phraseMap: { "check the thing": "check the server status" },
  metrics: { intentMatchRate: 95.5, calibrationIndex: 0.92 }
}`,
                    azure: 'Profiles stored in Azure App Service file system with backup retention'
                }
            },
            {
                type: 'external',
                title: '🎙️ Deepgram STT API',
                description: 'Audio buffer is sent from Azure to Deepgram Speech-to-Text API with HMLCP-generated custom vocabulary keywords. Each keyword is boosted to improve recognition of technical terms, domain-specific vocabulary, and user-specific language patterns.',
                data: '📊 Data Flow: Audio + Keywords → Raw Transcription Text + Confidence Score',
                code: `// SERVER: conference-server.js:87-110
async function transcribeAudio(audioBuffer, language, customVocab = []) {
  const options = {
    model: 'nova-2',
    language: languageMap[language]?.deepgram || 'en-US',
    smart_format: true,
    punctuate: true,
    utterances: false
  };

  // HMLCP: Add custom vocabulary if provided
  if (customVocab && customVocab.length > 0) {
    options.keywords = customVocab.map(v => \`\${v.phrase}:\${v.boost}\`);
    // Example: ["Kubernetes:25", "PostgreSQL:25", "Azure:25"]
  }

  const { result } = await deepgram.listen.prerecorded.transcribeFile(
    audioBuffer, options
  );

  return { text: result.results.channels[0].alternatives[0].transcript };
}`,
                details: {
                    layer: '🔴 External API - Deepgram (from Azure)',
                    technology: 'Deepgram Nova-2 Model with Custom Vocabulary',
                    implementation: [
                        'Audio sent from Azure to Deepgram prerecorded.transcribeFile endpoint',
                        'Nova-2 model provides state-of-the-art accuracy',
                        'Custom keywords array boosts recognition probability',
                        'Boost value 25 = high confidence for those terms',
                        'smart_format automatically handles formatting',
                        'Returns transcription + confidence score'
                    ],
                    files: [
                        'conference-server.js:87-110 - transcribeAudio function',
                        'conference-server.js:335-339 - STT invocation with customVocab'
                    ],
                    performance: '~200-500ms per audio chunk (Azure → Deepgram)',
                    integration: 'HMLCP generates keywords from user profile biasTerms',
                    example: `Input Audio: "I need to check the thing in kubernetes"
Keywords: ["Kubernetes:25", "PostgreSQL:25", "Azure:25"]
Output: "I need to check the thing in Kubernetes"
Confidence: 0.95

WITHOUT custom vocab: "I need to check the thing in cooper nettie's"
WITH custom vocab: "I need to check the thing in Kubernetes" ✓`
                }
            },
            {
                type: 'hmlcp',
                title: '🔄 ULO Layer Processing',
                description: 'The User Linguistic Overlay (ULO) is the core of HMLCP running on Azure. It applies personalized phrase mappings to transform the raw transcription into the user\'s intended meaning. This handles colloquialisms, shortcuts, and user-specific language patterns learned over time.',
                data: '📊 Data Flow: Raw Transcription → Processed Transcription (Intent-Aligned)',
                code: `// SERVER: conference-server.js:366
// HMLCP: Apply ULO layer for personalized linguistic processing
const processedTranscription = uloLayer.apply(transcription);

// ULO Layer Implementation (hmlcp/ulo-layer.js)
apply(text) {
  let processed = text;

  // Apply all phrase mappings from user profile
  for (const [pattern, replacement] of Object.entries(this.phraseMap)) {
    const regex = new RegExp(pattern, 'gi');
    processed = processed.replace(regex, replacement);
  }

  return processed;
}

// Store sample for future pattern analysis
profile.addTextSample(transcription);`,
                details: {
                    layer: '🟢 HMLCP System - User Linguistic Overlay (Azure Runtime)',
                    technology: 'Pattern Matching + Machine Learning',
                    implementation: [
                        'Applies phrase mappings from user profile in order',
                        'Case-insensitive regex matching for flexible recognition',
                        'Transforms colloquialisms to formal intent',
                        'Handles domain-specific shortcuts and abbreviations',
                        'Stores raw transcription for pattern analysis',
                        'Learning improves over time with user corrections',
                        'All processing happens server-side on Azure'
                    ],
                    files: [
                        'conference-server.js:366 - ULO application',
                        'hmlcp/ulo-layer.js:apply() - Core transformation logic',
                        'hmlcp/ulo-layer.js:learnFromCorrection() - Learning system'
                    ],
                    performance: '<1ms (simple string replacements)',
                    examples: `Phrase Map Examples:
┌────────────────────────────┬──────────────────────────────┐
│ Raw Transcription          │ Processed Output             │
├────────────────────────────┼──────────────────────────────┤
│ "check the thing"          │ "check the server status"    │
│ "the kubernetes"           │ "Kubernetes"                 │
│ "restart the stuff"        │ "restart the application"    │
│ "db query"                 │ "database query"             │
│ "ci cd pipeline"           │ "CI/CD pipeline"             │
└────────────────────────────┴──────────────────────────────┘`,
                    metrics: 'Intent Match Rate target: ≥95% | Calibration Index target: ≥0.9'
                }
            },
            {
                type: 'external',
                title: '🌐 DeepL Translation API',
                description: 'The PROCESSED transcription (cleaned by ULO) is sent from Azure to DeepL for translation. This is crucial - DeepL receives the user\'s intended meaning, not the raw STT output, resulting in much more accurate translations.',
                data: '📊 Data Flow: Processed Text (Source Lang) → Translated Text (Target Lang)',
                code: `// SERVER: conference-server.js:400-404
const translatedText = await translateText(
  finalTranscription,  // ← ULO-processed text, NOT raw transcription
  participant.language,
  targetParticipant.language
);

// DeepL Integration from Azure
async function translateText(text, sourceLang, targetLang) {
  const response = await fetch('https://api-free.deepl.com/v2/translate', {
    method: 'POST',
    headers: {
      'Authorization': \`DeepL-Auth-Key \${DEEPL_API_KEY}\`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      text: [text],
      source_lang: sourceLang.toUpperCase(),
      target_lang: targetLang.toUpperCase()
    })
  });

  const data = await response.json();
  return data.translations[0].text;
}`,
                details: {
                    layer: '🔴 External API - DeepL (from Azure)',
                    technology: 'DeepL Neural Machine Translation',
                    implementation: [
                        'Receives PROCESSED text from ULO (not raw STT)',
                        'Neural translation with context awareness',
                        'Supports 30+ languages',
                        'Maintains technical term accuracy',
                        'Preserves formatting and punctuation',
                        'Returns high-quality natural translation'
                    ],
                    files: [
                        'conference-server.js:400-404 - Translation invocation',
                        'conference-server.js:140-165 - translateText function'
                    ],
                    performance: '~300-800ms per translation (Azure → DeepL)',
                    integration: 'HMLCP ULO ensures accurate source text before translation',
                    example: `WITHOUT HMLCP ULO:
Raw STT: "I need to check the thing in kubernetes"
DeepL Translation (en→es): "Necesito revisar la cosa en kubernetes"
❌ POOR: "la cosa" (the thing) is vague

WITH HMLCP ULO:
Processed: "I need to check the server status in Kubernetes"
DeepL Translation (en→es): "Necesito verificar el estado del servidor en Kubernetes"
✓ EXCELLENT: Clear, technical, accurate`
                }
            },
            {
                type: 'external',
                title: '🗣️ Azure Text-to-Speech API',
                description: 'The translated text is converted to natural-sounding speech using Azure Cognitive Services TTS. High-quality neural voices are used for natural prosody and intonation.',
                data: '📊 Data Flow: Translated Text → MP3 Audio Buffer',
                code: `// SERVER: conference-server.js:425-435
const audioData = await synthesizeSpeech(
  translatedText,
  targetParticipant.language
);

// Azure TTS Integration (Azure to Azure)
async function synthesizeSpeech(text, language) {
  const sdk = require('microsoft-cognitiveservices-speech-sdk');

  const speechConfig = sdk.SpeechConfig.fromSubscription(
    AZURE_SPEECH_KEY,
    AZURE_SPEECH_REGION
  );

  speechConfig.speechSynthesisVoiceName = voiceMap[language];
  speechConfig.speechSynthesisOutputFormat =
    sdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3;

  const synthesizer = new sdk.SpeechSynthesizer(speechConfig);

  return new Promise((resolve, reject) => {
    synthesizer.speakTextAsync(
      text,
      result => resolve(result.audioData),
      error => reject(error)
    );
  });
}`,
                details: {
                    layer: '🔴 External API - Azure Cognitive Services',
                    technology: 'Azure Neural Text-to-Speech',
                    implementation: [
                        'Neural voice models for natural speech',
                        'Language-specific voice selection',
                        'MP3 format at 16kHz, 32kbps',
                        'Supports prosody, emphasis, and breaks',
                        'High-quality audio output',
                        'Automatic language detection and voice matching',
                        'Direct Azure-to-Azure communication for low latency'
                    ],
                    files: [
                        'conference-server.js:425-435 - TTS invocation',
                        'conference-server.js:170-195 - synthesizeSpeech function'
                    ],
                    performance: '~400-1000ms per synthesis (optimized Azure internal network)',
                    voices: `Voice Mapping:
• English (en): en-US-AriaNeural
• Spanish (es): es-ES-ElviraNeural
• French (fr): fr-FR-DeniseNeural
• German (de): de-DE-KatjaNeural
• Italian (it): it-IT-ElsaNeural`,
                    quality: 'Neural voices with natural intonation and prosody',
                    azure: 'Optimized latency using Azure-internal network routing'
                }
            },
            {
                type: 'internal',
                title: '🔊 Deliver to Client',
                description: 'The synthesized audio is sent from Azure server back to the client browser via WebSocket along with original and translated text for display. The client automatically plays the audio and shows the transcription.',
                data: '📊 Data Flow: Audio Buffer + Metadata → Client Browser via Azure',
                code: `// SERVER: conference-server.js:441-456
socket.to(roomId).emit("translated-audio", {
  from: participant.username,
  originalText: transcription,
  processedText: processedTranscription,
  translatedText: translatedText,
  audioData: audioData.toString("base64"),
  sourceLanguage: participant.language,
  targetLanguage: targetParticipant.language,
  timing: {
    totalLatency: Date.now() - timing.startTime,
    sttTime: timing.sttEnd - timing.sttStart,
    uloTime: timing.uloEnd - timing.uloStart,
    translationTime: timing.translationEnd - timing.translationStart,
    ttsTime: timing.ttsEnd - timing.ttsStart
  }
});

// CLIENT: public/index.html
socket.on("translated-audio", (data) => {
  // Display text
  displayTranscription(data.originalText, data.translatedText);

  // Play audio
  const audio = new Audio("data:audio/mp3;base64," + data.audioData);
  audio.play();
});`,
                details: {
                    layer: '🔵 Server Internal + Client Browser',
                    technology: 'Socket.IO WebSocket + Web Audio API',
                    implementation: [
                        'Audio encoded as base64 for WebSocket transmission',
                        'Complete timing metrics included for monitoring',
                        'Original, processed, and translated text sent',
                        'Client receives event via Socket.IO listener',
                        'Audio automatically decoded and played',
                        'Text displayed in chat interface',
                        'Performance metrics logged to console',
                        'Azure WebSocket support ensures reliable delivery'
                    ],
                    files: [
                        'conference-server.js:441-456 - Server emit',
                        'public/index.html - Client event handler'
                    ],
                    performance: '~10-50ms WebSocket transmission (Azure → Client)',
                    metadata: `Transmitted Data:
• from: username
• originalText: raw STT output
• processedText: ULO-processed output
• translatedText: DeepL translation
• audioData: base64 MP3
• sourceLanguage, targetLanguage
• timing: complete latency breakdown`,
                    azure: 'Azure App Service WebSocket support with always-on for reliable connections'
                }
            },
            {
                type: 'storage',
                title: '💾 Auto-Save User Profile',
                description: 'Every 5 minutes, all loaded user profiles are automatically saved to persistent storage on Azure. This includes collected text samples, learned phrase mappings, updated metrics, and bias terms. Profiles are saved as JSON files in Azure App Service file system.',
                data: '📊 Data Flow: In-Memory Profile → JSON File (Azure File System: hmlcp/profiles/*.json)',
                code: `// SERVER: conference-server.js:743-761
// Auto-save all user profiles every 5 minutes
setInterval(async () => {
  console.log('[HMLCP] Auto-saving user profiles...');

  let savedCount = 0;
  for (const [key, { profile }] of userProfiles.entries()) {
    try {
      await profile.save();
      savedCount++;
    } catch (error) {
      console.error(\`[HMLCP] Error saving profile \${key}:\`, error);
    }
  }

  console.log(\`[HMLCP] Saved \${savedCount} user profiles\`);
}, 5 * 60 * 1000); // Every 5 minutes

// UserProfile.save() implementation (hmlcp/user-profile.js)
async save() {
  this.lastUpdated = new Date().toISOString();
  const data = JSON.stringify(this, null, 2);
  const filePath = \`./hmlcp/profiles/\${this.userId}_\${this.language}.json\`;
  await fs.promises.writeFile(filePath, data, 'utf8');
}`,
                details: {
                    layer: '🟡 Persistent Storage - Azure App Service File System',
                    technology: 'JSON Files + Node.js fs module + Azure Storage',
                    implementation: [
                        'Profiles stored in hmlcp/profiles/ directory on Azure',
                        'Filename format: <userId>_<language>.json',
                        'Auto-save runs every 5 minutes (300000ms)',
                        'All in-memory profiles saved to disk',
                        'lastUpdated timestamp automatically updated',
                        'Pretty-printed JSON (2-space indent) for readability',
                        'Error handling prevents data loss',
                        'Azure file system persists across app restarts'
                    ],
                    files: [
                        'conference-server.js:743-761 - Auto-save interval',
                        'hmlcp/user-profile.js:save() - Persistence logic',
                        'hmlcp/profiles/*.json - Stored profiles on Azure'
                    ],
                    performance: 'Async non-blocking write (~5-10ms per profile)',
                    structure: `Profile JSON Structure:
{
  "userId": "testuser",
  "language": "en",
  "created": "2025-10-12T20:00:00.000Z",
  "lastUpdated": "2025-10-12T21:05:26.169Z",
  "tone": "neutral",
  "avgSentenceLength": 12,
  "directness": 0.85,
  "ambiguityTolerance": 0.3,
  "lexicalBias": ["technical", "formal"],
  "phraseMap": {
    "check the thing": "check the server status",
    "restart the stuff": "restart the application"
  },
  "biasTerms": ["Kubernetes", "PostgreSQL", "Azure", "Docker"],
  "metrics": {
    "intentMatchRate": 95.5,
    "correctionFrequency": 0.05,
    "semanticDrift": 0.02,
    "calibrationIndex": 0.92
  }
}`,
                    backup: 'Profiles persist across server restarts on Azure App Service',
                    azure: 'Azure App Service file system with built-in persistence and backup capabilities'
                }
            }
        ];

        let currentStep = 0;

        function renderSteps() {
            const container = document.getElementById('flowContainer');
            container.innerHTML = steps.map((step, index) => {
                const detailsHtml = step.details ? `
                    <div class="step-details" id="details-${index}">
                        <div class="details-section">
                            <div class="details-title">🏗️ Layer & Technology</div>
                            <div class="details-content">
                                <strong>Layer:</strong> ${step.details.layer}<br>
                                <strong>Technology:</strong> ${step.details.technology}
                            </div>
                        </div>

                        <div class="details-section">
                            <div class="details-title">⚙️ Implementation Details</div>
                            <ul class="details-list">
                                ${step.details.implementation.map(item => `<li>${item}</li>`).join('')}
                            </ul>
                        </div>

                        <div class="details-section">
                            <div class="details-title">📁 File References</div>
                            <div class="details-content">
                                ${step.details.files.map(file =>
                                    `<div style="margin: 5px 0;"><span class="file-ref">${file}</span></div>`
                                ).join('')}
                            </div>
                        </div>

                        <div class="details-section">
                            <div class="details-title">⚡ Performance</div>
                            <div class="details-content">
                                <span class="metric">${step.details.performance}</span>
                            </div>
                        </div>

                        ${step.details.azure ? `
                            <div class="details-section">
                                <div class="details-title">☁️ Azure Integration</div>
                                <div class="details-content">${step.details.azure}</div>
                            </div>
                        ` : ''}

                        ${step.details.example ? `
                            <div class="details-section">
                                <div class="details-title">💡 Example</div>
                                <div class="step-code">${step.details.example.replace(/</g, '&lt;').replace(/>/g, '&gt;')}</div>
                            </div>
                        ` : ''}

                        ${step.details.examples ? `
                            <div class="details-section">
                                <div class="details-title">💡 Examples</div>
                                <div class="step-code">${step.details.examples.replace(/</g, '&lt;').replace(/>/g, '&gt;')}</div>
                            </div>
                        ` : ''}

                        ${step.details.integration ? `
                            <div class="details-section">
                                <div class="details-title">🔗 HMLCP Integration</div>
                                <div class="details-content">${step.details.integration}</div>
                            </div>
                        ` : ''}

                        ${step.details.dataStructure ? `
                            <div class="details-section">
                                <div class="details-title">📊 Data Structure</div>
                                <div class="step-code">${step.details.dataStructure.replace(/</g, '&lt;').replace(/>/g, '&gt;')}</div>
                            </div>
                        ` : ''}

                        ${step.details.structure ? `
                            <div class="details-section">
                                <div class="details-title">📊 Data Structure</div>
                                <div class="step-code">${step.details.structure.replace(/</g, '&lt;').replace(/>/g, '&gt;')}</div>
                            </div>
                        ` : ''}

                        ${step.details.metrics ? `
                            <div class="details-section">
                                <div class="details-title">📈 Metrics</div>
                                <div class="details-content">${step.details.metrics}</div>
                            </div>
                        ` : ''}

                        ${step.details.voices ? `
                            <div class="details-section">
                                <div class="details-title">🎤 Voice Configuration</div>
                                <div class="step-code">${step.details.voices.replace(/</g, '&lt;').replace(/>/g, '&gt;')}</div>
                            </div>
                        ` : ''}

                        ${step.details.metadata ? `
                            <div class="details-section">
                                <div class="details-title">📦 Transmitted Metadata</div>
                                <div class="step-code">${step.details.metadata.replace(/</g, '&lt;').replace(/>/g, '&gt;')}</div>
                            </div>
                        ` : ''}

                        ${step.details.backup ? `
                            <div class="details-section">
                                <div class="details-title">💾 Backup & Recovery</div>
                                <div class="details-content">${step.details.backup}</div>
                            </div>
                        ` : ''}

                        ${step.details.dataFormat ? `
                            <div class="details-section">
                                <div class="details-title">📋 Data Format</div>
                                <div class="details-content">${step.details.dataFormat}</div>
                            </div>
                        ` : ''}

                        ${step.details.quality ? `
                            <div class="details-section">
                                <div class="details-title">✨ Quality</div>
                                <div class="details-content">${step.details.quality}</div>
                            </div>
                        ` : ''}
                    </div>
                ` : '';

                return `
                    <div class="step ${step.type}" id="step-${index}">
                        <div class="step-header">
                            <div class="step-number">${index + 1}</div>
                            <div class="step-content">
                                <div class="step-title">
                                    ${step.title}
                                    <span class="badge badge-${step.type}">
                                        ${step.type === 'client' ? 'CLIENT LAYER' :
                                          step.type === 'external' ? 'EXTERNAL API' :
                                          step.type === 'hmlcp' ? 'HMLCP SYSTEM' :
                                          step.type === 'storage' ? 'STORAGE' : 'SERVER INTERNAL'}
                                    </span>
                                </div>
                                <div class="step-description">${step.description}</div>
                                <div class="step-data">${step.data}</div>
                                <div class="step-code">${step.code.replace(/</g, '&lt;').replace(/>/g, '&gt;')}</div>
                                ${step.details ? `<button class="drill-btn" onclick="toggleDetails(${index})">Show Technical Details</button>` : ''}
                                ${detailsHtml}
                            </div>
                        </div>
                    </div>
                `;
            }).join('');
        }

        function toggleDetails(index) {
            const details = document.getElementById(`details-${index}`);
            const btn = details.previousElementSibling;

            if (details.classList.contains('expanded')) {
                details.classList.remove('expanded');
                btn.textContent = 'Show Technical Details';
                btn.classList.remove('expanded');
            } else {
                details.classList.add('expanded');
                btn.textContent = 'Hide Technical Details';
                btn.classList.add('expanded');
            }
        }

        function updateStep() {
            document.querySelectorAll('.step').forEach(step => {
                step.classList.remove('active');
            });

            for (let i = 0; i <= currentStep; i++) {
                document.getElementById(`step-${i}`).classList.add('active');
            }

            const progress = ((currentStep + 1) / steps.length) * 100;
            document.getElementById('progress').style.width = progress + '%';

            const dataFlow = document.getElementById('dataFlow');
            if (currentStep < steps.length) {
                dataFlow.textContent = `Step ${currentStep + 1}/${steps.length}: ${steps[currentStep].title}`;
            }

            const currentStepElement = document.getElementById(`step-${currentStep}`);
            if (currentStepElement) {
                currentStepElement.scrollIntoView({ behavior: 'smooth', block: 'center' });
            }
        }

        function nextStep() {
            if (currentStep < steps.length - 1) {
                currentStep++;
                updateStep();
            }
        }

        function prevStep() {
            if (currentStep > 0) {
                currentStep--;
                updateStep();
            }
        }

        function restart() {
            currentStep = 0;
            updateStep();
        }

        document.addEventListener('keydown', (e) => {
            if (e.key === 'ArrowRight') nextStep();
            if (e.key === 'ArrowLeft') prevStep();
            if (e.key === 'Home') restart();
        });

        renderSteps();
        updateStep();
    </script>
</body>
</html>
