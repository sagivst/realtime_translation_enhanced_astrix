

ðŸŽ§ Gateway â†” Translation Server Integration Specification


â¸»

1. Purpose

This document describes the real-time integration between the open-source Node.js Gateway
(from the nikhilbadyal/asterisk-external-media-gateway project)
and the Unified Translation Server that handles all AI functions
(ASR, Translation, TTS, Emotion, etc.).

It explains how the Gateway communicates with the Translation Server,
what data format is exchanged, and why no additional configuration in Asterisk (ExternalMedia, bridges, etc.) is required once the Gateway is active.

â¸»

2. Architecture Overview

flowchart LR
    AST["Asterisk (ExternalMedia RTP)"]
    GW["Open-Source Node.js Gateway"]
    TR["Unified Translation Server (AI Pipeline)"]

    AST <--> |RTP PCM 16kHz| GW
    GW <--> |WebSocket Audio Stream (PCM 16kHz)| TR

Summary:
	â€¢	Asterisk streams audio via ExternalMedia channels to the Gateway (standard RTP).
	â€¢	Gateway receives this audio, sends it to your Translation Server over WebSocket (or HTTPS streaming),
receives the translated audio back, and returns it to Asterisk.
	â€¢	The process is fully duplex and continuous, with sub-150 ms total latency.

â¸»

3. Key Design Principle

Asterisk does not need to know anything about the Translation Server or AI services.
Once the ExternalMedia channels are created (by default configuration),
the Gateway handles all routing, synchronization, and AI communication automatically.

There is no need to:
	â€¢	modify Asterisk dialplan logic,
	â€¢	reconfigure ExternalMedia per session,
	â€¢	or create any new media bridges.

Everything happens transparently between the Gateway and your Translation Server.

â¸»

4. Data Flow (Step-by-Step)

Step	Direction	Action	Description
1	Asterisk â†’ Gateway	RTP (20 ms PCM frames)	The raw mic audio from each participant is streamed via ExternalMedia.
2	Gateway â†’ Translation Server	WebSocket audio stream	The Gateway forwards the raw audio as continuous PCM data to your Translation Server endpoint.
3	Translation Server	Internal AI pipeline	ASR â†’ Translation â†’ TTS (optionally Emotion or Voice Profile).
4	Translation Server â†’ Gateway	WebSocket PCM return stream	The translated audio is streamed back in real-time.
5	Gateway â†’ Asterisk	RTP	The Gateway re-encapsulates the translated PCM data into RTP and sends it back to Asterisk.


â¸»

5. Connection Specifications

Parameter	Specification
Protocol (Asterisk â†” Gateway)	RTP (UDP)
Protocol (Gateway â†” Translation Server)	WebSocket (full-duplex) or HTTP/2 streaming
Audio Format	PCM16 (mono, 16 kHz, 20 ms frame)
Average Round-Trip Latency	100â€“140 ms
Buffer Handling	Gateway keeps ~2â€“3 frames (â‰ˆ60 ms) buffer to maintain sync
Session Lifecycle	WebSocket opens when call starts, closes when bridge ends
Error Handling	If Translation Server is unreachable, Gateway sends silent frames to Asterisk to keep session stable


â¸»

6. Translation Server Endpoint Requirements

Your Translation Server should expose one unified endpoint, such as:

wss://translate.myservice.ai/session

or

https://translate.myservice.ai/api/audio

Expected Behavior
	â€¢	Input: continuous PCM audio stream (mono, 16-bit, 16 kHz)
	â€¢	Output: continuous PCM audio stream (same spec)
	â€¢	The translation logic inside (ASR â†’ Translate â†’ TTS) remains completely opaque to the Gateway.
	â€¢	Each session (per call leg) corresponds to a separate WebSocket connection.

â¸»

7. Session Handling

When a call begins (for example, between extensions 7000 and 7001):
	â€¢	Two ExternalMedia channels are created automatically by the ARI logic.
	â€¢	The Gateway detects each new media session and opens a new WebSocket to your Translation Server.
	â€¢	One socket per direction:
	â€¢	English â†’ French
	â€¢	French â†’ English
	â€¢	When the call ends, the WebSocket sessions are closed and all buffers flushed.

â¸»

8. Synchronization and Timing

The Gateway continuously maps each 20 ms RTP frame from Asterisk
to a 20 ms PCM segment in the WebSocket stream.
Incoming translated audio is timestamped and reinjected with the same sequence numbers.

This ensures:
	â€¢	No drift between the two directions.
	â€¢	Continuous playback without packet gaps.
	â€¢	Full duplex conversation within human-perceptible thresholds.

â¸»

9. Monitoring & Debugging

Task	Tool / Method
Verify RTP from Asterisk	rtp set debug on in Asterisk CLI
Check WebSocket sessions	Gateway logs (connection open/close per session)
Measure round-trip latency	Timestamped frame comparison (Asterisk â†” Translation Server)
Handle translation server downtime	Gateway plays short silence frames to maintain bridge stability


â¸»

10. Deployment Model

Component	Location	Notes
Asterisk	Same machine or LAN	Must see the Gatewayâ€™s UDP port directly
Gateway (Node.js)	Local or nearby edge node	Ideal latency â‰¤ 10 ms between Asterisk and Gateway
Translation Server	Cloud or on-prem cluster	Handles AI logic (ASR, translation, voice synthesis)


â¸»

11. Summary

âœ… The open-source Gateway acts as the only interface between the PBX and your AI system.
âœ… Asterisk requires no additional setup once ExternalMedia channels are in place.
âœ… The Translation Server sees only clean audio â€” no telephony logic.
âœ… Audio flows seamlessly both ways via RTPâ†”WebSocket, with minimal latency.
âœ… Failover and silence handling ensure uninterrupted conversation even if AI temporarily stalls.

â¸»

12. Key Takeaway

Once the Node.js Gateway is installed and configured,
there is nothing more to configure inside Asterisk.
All logic for translation, voice generation, and synchronization lives in the Gateway and your Translation Server.

