
# Realtime Uplink Capture via Asterisk ExternalMedia (direction=read)

## ðŸŽ¯ Objective
Capture a **clean, continuous microphone stream** (uplink only) from any participant in real time,  
directly from Asterisk, with minimal latency (~20 ms frame pacing).

This configuration uses **Asteriskâ€™s built-in `chan_externalmedia`** with:

direction=read

so only the *participantâ€™s microphone audio* (TX) is sent to your Orchestrator â€”  
no mixed playback or echo-cancelled data.

---

## âš™ï¸ 1. Asterisk Dialplan Configuration

```conf
[ai-uplink]
exten => 6001,1,NoOp(Uplink capture for participant)
 same => n,ExternalMedia(
    format=slin16,                  ; 16-bit PCM
    direction=read,                 ; TX (mic) only
    transport=websocket,            ; duplex over WS
    remote_host=orchestrator.local, ; your AI server
    remote_port=5050,               ; ingest port
    buffer_ms=20                    ; frame pacing
 )
 same => n,ConfBridge(1234)         ; bridge_softmix still handles others
 same => n,Hangup()

Parameter details

Parameter	Description	Recommended
format	Audio format	slin16 (16-bit PCM)
direction	Direction of flow	read (uplink only)
transport	Data link	websocket (TCP full-duplex)
buffer_ms	Frame size	20 for 50 fps cadence
remote_host / remote_port	Orchestrator endpoint	wss://â€¦ or LAN IP
codec_passthrough	Optional	no (ensure slin16 consistency)

With direction=read, Asterisk sends a 20 ms frame every tick,
but does not expect any return frame â€” it is one-way (uplink only).

â¸»

ðŸ“¦ 2. Data Stream Specification

Each 20 ms packet contains:
	â€¢	Raw PCM (s16le) â€“ 16 kHz, mono
	â€¢	Fixed payload: 640 bytes per frame
	â€¢	Cadence: exactly 50 frames/second

Binary frame structure:

[PCM 640 bytes]

Optionally, you can prepend your own metadata:

{"seq":184225,"ts_mono_ms":1739630112.204}


â¸»

ðŸ”Œ 3. Orchestrator Ingest (Receiver Side)

Example (Python/async WebSocket):

import asyncio, websockets, sounddevice as sd

async def uplink_receiver():
    async with websockets.connect("ws://0.0.0.0:5050") as ws:
        samplerate = 16000
        with sd.OutputStream(samplerate=samplerate, channels=1, dtype='int16') as player:
            seq = 0
            while True:
                pcm = await ws.recv()   # 640-byte PCM frame
                seq += 1
                # immediate handoff: fan-out to Deepgram, Hume, etc.
                process_frame(seq, pcm)
                player.write(pcm)       # optional: hear the raw uplink

process_frame() can forward each frame in parallel to:
	â€¢	Deepgram ASR (WebSocket) â€“ binary PCM feed
	â€¢	Hume EVI (WebSocket) â€“ binary PCM + optional text hints
	â€¢	Local storage / VAD / Diarization â€“ as needed

â¸»

ðŸ§  4. Verification (Tap-listen)

Because direction=read is uplink only, you can safely monitor it in real time
without feedback or echo.
Attach a small Audio Tap module to play or record the same PCM frames (as in your QA spec):

tap_q.feed(seq, pcm)  # enqueue for monitoring

Playback is perfectly natural if frames are streamed continuously at 20 ms cadence.

â¸»

ðŸ“Š 5. Performance & Timing

Stage	Expected latency	Notes
Asterisk capture (frame ready)	0â€“2 ms	internal buffer only
ExternalMedia frame send	1â€“3 ms	WebSocket/TCP overhead
Orchestrator receive â†’ dispatch	2â€“5 ms	depends on LAN
Total uplink delay	~8â€“10 ms typical	well below 20 ms tick

Clock source:
Asteriskâ€™s internal scheduler (20 ms).
Your Orchestrator must stay frame-synchronous â€” never await downstream consumers.

â¸»

ðŸ§© 6. Recommended use cases

Purpose	Why use direction=read
ASR / Emotion Analysis	Provides the cleanest microphone feed
Training datasets	Single-speaker uplink, no mix-minus artifacts
Live QA / Monitoring	Zero echo risk; easy playback
Low-latency AI assist	Ideal for <200 ms pipeline response


â¸»

âœ… 7. Key Advantages
	â€¢	Direct microphone capture (no mix, no ducking)
	â€¢	No round-trip blocking â€” one-way uplink only
	â€¢	Stable 20 ms cadence managed by Asterisk
	â€¢	Simple configuration (no ARI scripting needed)
	â€¢	Works seamlessly with your Orchestrator fan-out layer

â¸»

ðŸ§­ 8. Comparison Summary

Mode	Direction	Data	Latency	Use Case
direction=both	TX+RX	Full duplex	~20â€“25 ms	translation loop
direction=read	TX only (mic)	uplink stream	~10 ms	ingestion, analysis
direction=write	RX only (speaker)	playback only	~10 ms	testing output


â¸»

ðŸ§© 9. Testing / QA checklist
	â€¢	Confirm ExternalMedia socket opens on Asterisk start (netstat or log).
	â€¢	Receive 50 frames/sec (640 bytes each).
	â€¢	No â€œUnderflow/Overrunâ€ warnings in Asterisk CLI.
	â€¢	Measured frame interval: 20 Â± 2 ms.
	â€¢	Verify same PCM content on audio tap and ASR feed.
	â€¢	Optional: record 5 s and play back concatenated â€” should sound natural.

â¸»

âœ… Summary

Using ExternalMedia(format=slin16, direction=read) gives you a dedicated uplink-only PCM stream at 20 ms intervals, ideal for ASR, emotion, and real-time analytics.
This method provides the cleanest signal path from the participantâ€™s microphone with <10 ms ingest latency, and integrates natively with your existing Orchestratorâ€™s fan-out design.



