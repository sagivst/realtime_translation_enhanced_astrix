

Technical Integration Document

Optimal Open-Source Method for Connecting Your AI Server to Hume AI (Emotion & Prosody API)

Version: 1.0

Audience: Backend Developers, AI Engineers

Scope: Real-time emotion/prosody analysis via Hume Streams API.

‚∏ª

1. Overview

Hume AI provides Emotion API and Prosody API that work in real time via:
	‚Ä¢	WebSocket Streams API ‚Üê BEST for speed + accuracy
	‚Ä¢	REST API for batch processing ‚Üê slower, not recommended for live systems

For maximum speed, lowest latency, and highest accuracy,
the optimal open-source integration approach is:

üëâ Hume Streams API over WebSockets + PCM 16 kHz input

And the best open-source library to use:

üëâ Official Hume SDKs (Node or Python)

Fully open-source and optimized, with streaming support.

‚∏ª

2. The Optimal Transport Method

‚≠ê WebSocket Streaming ‚Üí Hume Streams API

This provides:
	‚Ä¢	Real-time processing
	‚Ä¢	Frame-by-frame analysis
	‚Ä¢	Lower latency vs REST
	‚Ä¢	Improved consistency of emotion/prosody detection
	‚Ä¢	Full-duplex communication
	‚Ä¢	Stable performance for continuous AI pipelines

REST ‚âà slow, batch-only
WebSockets ‚âà optimal for your AI server

‚∏ª

3. Ideal Audio Format

Hume supports multiple formats, but the best performance comes from:

Parameter	Value
Encoding	PCM 16-bit, S16LE
Channels	Mono
Sample Rate	16,000 Hz
Chunk Size	20‚Äì50 ms chunks

This perfectly matches your existing STT pipeline (Deepgram ‚Üí PCM16).

‚∏ª

4. Recommended Open-Source Libraries

Hume publishes official SDKs:

‚úî Node.js SDK (Open Source)

https://github.com/humeai/hume/tree/main/sdk/js

‚úî Python SDK (Open Source)

https://github.com/humeai/hume/tree/main/sdk/python

Why use these?
	‚Ä¢	Built-in WebSocket client
	‚Ä¢	Supports Prosody + Language models
	‚Ä¢	Automatic reconnection
	‚Ä¢	Low overhead ‚Üí high throughput
	‚Ä¢	Perfect for event-streaming architectures
	‚Ä¢	Production-grade error handling

Using these SDKs is significantly faster and more reliable than hand-writing your own WS client.

‚∏ª

5. Node.js Example (Hume Streams API)

import { HumeClient, HumeStreamClient } from "hume";

const client = new HumeClient({ apiKey: process.env.HUME_API_KEY });
const streamClient = new HumeStreamClient({ apiKey: process.env.HUME_API_KEY });

const ws = await streamClient.connect({
  models: { prosody: {} },
});

ws.on("message", (msg) => {
  console.log("Emotion/Prosody:", msg);
});

// Send PCM16 chunks (20ms @ 16 kHz)
function sendPCM(chunk) {
  ws.sendBinary(chunk);
}


‚∏ª

6. Python Example (Hume Streams API)

from hume import HumeStreamClient
from hume.models.config import ProsodyConfig

client = HumeStreamClient(api_key="YOUR_KEY")
config = ProsodyConfig()

with client.connect([config]) as ws:
    # ws.send_audio accepts PCM16 bytes
    ws.send_audio(chunk)  
    for msg in ws:
        print("Emotion/Prosody:", msg)


‚∏ª

7. Pipeline Architecture (Recommended)

Audio Input ‚Üí PCM 16kHz
      ‚Üì
AI Server (Python/Node)
      ‚Üì
WebSocket Stream ‚Üí Hume Streams API
      ‚Üì
Emotion / Prosody JSON scores (realtime)
      ‚Üì
Your AI logic (routing / scoring / translation)

This ensures:
	‚Ä¢	lowest latency
	‚Ä¢	maximum emotional accuracy
	‚Ä¢	smooth integration with STT/TTS pipelines

‚∏ª

8. Best Practices for Maximum Accuracy

‚úî 1. Use 16 kHz PCM

Other formats add decode overhead or degrade emotion cues.

‚úî 2. Keep frames small (20‚Äì40 ms)

Hume‚Äôs emotion model performs better with small consistent chunks.

‚úî 3. Normalize volume

Hume responds better to normalized audio (-3 dBFS).

‚úî 4. Avoid compressed codecs (Opus/AAC)

Compression reduces emotional cues.

‚úî 5. Keep WebSocket persistent

Avoid reopening for every message (adds latency).

‚úî 6. Use Hume‚Äôs Prosody model for emotion over time

Deep integration with your translation pipeline.

‚∏ª

9. When NOT to Use REST

Avoid REST unless:
	‚Ä¢	You‚Äôre analyzing full recordings
	‚Ä¢	You don‚Äôt need real-time output
	‚Ä¢	Latency is not critical

For your use-case (real-time AI conversation):

üëâ Always use Hume Streams API

‚∏ª

10. Final Recommendation

‚≠ê Use Hume‚Äôs official open-source SDK + WebSocket Streams + PCM 16kHz

for the fastest, most stable, and most accurate integration with Hume AI.

This is the industry-standard approach for emotional analysis in:
	‚Ä¢	real-time translation
	‚Ä¢	conversational AI
	‚Ä¢	telephony systems
	‚Ä¢	multi-model pipelines (Deepgram ‚Üí DeepL ‚Üí ElevenLabs ‚Üí Hume)
